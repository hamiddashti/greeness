{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_funs \n",
    "import numpy as np \n",
    "import xarray as xr \n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "def get_filenames(host, name_key):\n",
    "    \"\"\" Get all the link names of files from NOAA repo\n",
    "    Argument:\n",
    "    host:: NOAA repo\n",
    "    name_key:: a keyword common in all file names (e.g. AVHRR)\n",
    "    \"\"\"\n",
    "    req = requests.get(host)\n",
    "    soup = BeautifulSoup(req.text, features=\"html.parser\")\n",
    "    pattern = re.compile(name_key)\n",
    "    filenames = []\n",
    "    for link in soup.find_all(\"a\", href=pattern):\n",
    "        fname = link.get('href')\n",
    "        filenames.append(fname)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data LAI/FPAR\n",
    "\n",
    "f_exist = glob.glob(\"/home/hamid/NASA_ABoVE/greeness/data/raw_data/noaa_cdr/lai_fpar/clipped/*\")\n",
    "already_downloaded= []\n",
    "for f in f_exist:\n",
    "    filepath = f\n",
    "    basename = os.path.basename(filepath)\n",
    "    already_downloaded.append(basename[8:])\n",
    "print(len(already_downloaded))\n",
    "\n",
    "data_dir = \"/home/hamid/NASA_ABoVE/greeness/working/data/\"\n",
    "years = np.arange(1984,2014)\n",
    "shp_file = data_dir + 'shp_files/CoreDomain_geographic.shp'\n",
    "tasks = []\n",
    "for year in years:\n",
    "\n",
    "    # host of the data\n",
    "    host = 'https://www.ncei.noaa.gov/data/avhrr-land-leaf-area-index-and-fapar/access/' + str(\n",
    "        year) + '/'\n",
    "    # Get all file names in that year directory\n",
    "    filenames = get_filenames(host=host, name_key=\"AVHRR\")\n",
    "\n",
    "    filenames = filenames\n",
    "    for file_name in filenames:\n",
    "        # print(file_name)\n",
    "        tmp = my_funs.clip_noaa_parallel(file_name, host, shp_file, data_dir+'raw_data/noaa_cdr/lai_fpar/','lai')\n",
    "        tasks.append(tmp)\n",
    "print(len(tasks))\n",
    "\n",
    "# with ProgressBar():\n",
    "#     dask.compute(*tasks)\n",
    "# ds = xr.open_mfdataset(data_dir+'raw_data/noaa_cdr/lai_fpar/*.nc')\n",
    "# ds.to_zarr(data_dir+'processed_data/noaa_nc/lai_fpar/noaa_lia_fpar_clipped_raw.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data NDVI\n",
    "f_exist = glob.glob(\"/home/hamid/NASA_ABoVE/greeness/data/raw_data/noaa_cdr/ndvi/clipped/*\")\n",
    "already_downloaded= []\n",
    "for f in f_exist:\n",
    "    filepath = f\n",
    "    basename = os.path.basename(filepath)\n",
    "    already_downloaded.append(basename[8:])\n",
    "print(len(already_downloaded))\n",
    "\n",
    "data_dir = \"/home/hamid/NASA_ABoVE/greeness/working/data/\"\n",
    "years = np.arange(1984,2014)\n",
    "shp_file = data_dir + 'shp_files/CoreDomain_geographic.shp'\n",
    "tasks = []\n",
    "for year in years:\n",
    "    # host of the data\n",
    "    host = 'https://www.ncei.noaa.gov/data/land-normalized-difference-vegetation-index/access/' + str(\n",
    "        year) + '/'\n",
    "    # Get all file names in that year directory\n",
    "    filenames = my_funs.get_filenames(host=host, name_key=\"AVHRR\")\n",
    "    \n",
    "    # Lazy download and clip each file and then remove the original global file\n",
    "    for file_name in filenames:\n",
    "        if file_name in already_downloaded:\n",
    "            continue\n",
    "        tmp = my_funs.clip_noaa_parallel(file_name, host, shp_file, data_dir+'raw_data/noaa_cdr/ndvi/','ndvi')\n",
    "        tasks.append(tmp)\n",
    "\n",
    "print(len(tasks))\n",
    "# # # Compute the lazy object\n",
    "# with ProgressBar():\n",
    "#     dask.compute(*tasks)\n",
    "# ds = xr.open_mfdataset(data_dir+'raw_data/noaa_cdr/ndvi/*.nc')\n",
    "# ds.to_zarr(data_dir+'processed_data/noaa_nc/ndvi/noaa_ndvi_clipped_raw.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data Reflectance\n",
    "f_exist = glob.glob(\"/home/hamid/NASA_ABoVE/greeness/working/data/raw_data/noaa_cdr/reflectance/*\")\n",
    "already_downloaded= []\n",
    "for f in f_exist:\n",
    "    filepath = f\n",
    "    basename = os.path.basename(filepath)\n",
    "    already_downloaded.append(basename[8:])\n",
    "print(len(already_downloaded))\n",
    "\n",
    "data_dir = \"/home/hamid/NASA_ABoVE/greeness/working/data/\"\n",
    "years = np.arange(1984,2014)\n",
    "shp_file = data_dir + 'shp_files/CoreDomain_geographic.shp'\n",
    "tasks = []\n",
    "for year in years:\n",
    "    # host of the data\n",
    "    host = 'https://www.ncei.noaa.gov/data/land-surface-reflectance/access/' + str(\n",
    "        year) + '/'\n",
    "    # Get all file names in that year directory\n",
    "    filenames = my_funs.get_filenames(host=host, name_key=\"AVHRR\")\n",
    "    filenames = filenames\n",
    "    # year_dir = data_dir + 'raw_data/noaa_cdr/' + str(year) + '/'\n",
    "    # # Create seperate directory for each year\n",
    "    # if not os.path.isdir(year_dir):\n",
    "    #     os.makedirs(year_dir)\n",
    "    # Lazy download and clip each file and then remove the original global file\n",
    "    for file_name in filenames:\n",
    "        tmp = my_funs.clip_noaa_parallel(file_name, host, shp_file, data_dir+'raw_data/noaa_cdr/reflectance/','reflectance')\n",
    "        tasks.append(tmp)\n",
    "# Compute the lazy objectfrom dask.diagnostics import ProgressBar\n",
    "print(len(tasks))\n",
    "with ProgressBar():\n",
    "    dask.compute(*tasks)\n",
    "ds = xr.open_mfdataset(data_dir+'raw_data/noaa_cdr/reflectance/*.nc')\n",
    "ds.to_zarr(data_dir+'processed_data/noaa_nc/reflectance/noaa_reflectance_clipped_raw.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geospatial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58d4357dc51a73699c5449b037ed9e8ebf9460004e4993ef846dc1036514c650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
