{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/hamiddashti/hamid/nasa_above/greeness/codes/src/my_funs.py:9: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n",
      "2023-05-29 19:58:55.260495: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-29 19:58:55.306737: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-29 19:58:55.307744: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-29 19:58:56.154126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from my_funs import est_trend\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import BallTree, DistanceMetric\n",
    "from causalimpact import CausalImpact\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "dir = \"/data/home/hamiddashti/hamid/nasa_above/greeness/\"\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lai = xr.open_dataarray(\n",
    "    dir + \"data/processed_data/noaa_nc/lai_fapar/resampled/lai_annual_resample_max.nc\"\n",
    ").rename({\"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "# ndvi_max = xr.open_dataarray(dir+\"data/processed_data/landsat/resampled/ndvi_annual_max.nc\")\n",
    "# ndvi_max = ndvi_max.sel(time=slice(\"1985\",\"2013\")).rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "# ndvi_max = ndvi_max/1e4\n",
    "# nir = xr.open_dataarray(dir+\"data/processed_data/landsat/resampled/nir.nc\")\n",
    "# nir = nir.sel(time=slice(\"1985\",\"2013\"))\n",
    "swi = xr.open_dataarray(dir + \"data/processed_data/swi/swi.nc\")\n",
    "# lai_max[\"time\"] = pd.date_range(\"1984\",\"2014\",freq = \"A\")\n",
    "lai = lai.sel(time=slice(\"1985\", \"2014\"))  # 1984 has many nan values\n",
    "arr = xr.open_dataarray(dir + \"data/arr_id.nc\")\n",
    "percent_cover = xr.open_dataarray(\n",
    "    dir + \"data/processed_data/percent_cover/percent_cover.nc\"\n",
    ")\n",
    "percent_cover = percent_cover.loc[\"1985\":\"2013\"]\n",
    "percent_cover = percent_cover.round(2)\n",
    "# If a class is 0 change it no nan to prevent false zeros in diff later\n",
    "percent_cover = percent_cover.where(percent_cover != 0)\n",
    "percent_cover[\"lat\"] = lai[\"lat\"]\n",
    "percent_cover[\"lon\"] = lai[\"lon\"]\n",
    "t = pd.date_range(start=\"1985\", end=\"2014\", freq=\"A-Dec\").year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = percent_cover.isel(band=[0, 2, 3])\n",
    "lc_diff_abs = abs(lc.diff(\"time\"))\n",
    "changed = (lc_diff_abs > 0.1).any([\"time\", \"band\"])\n",
    "\n",
    "lai_changed = lai.where(changed == True)\n",
    "lai_notchanged = lai.where(changed == False)\n",
    "lai_changed.to_netcdf(dir + \"working/lai_changed_all.nc\")\n",
    "lai_notchanged.to_netcdf(dir + \"working/lai_notchanged_all.nc\")\n",
    "changed.to_netcdf(dir + \"working/changed.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/hamiddashti/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/neighbors/_distance_metric.py:10: FutureWarning: sklearn.neighbors.DistanceMetric has been moved to sklearn.metrics.DistanceMetric in 1.0. This import path will be removed in 1.3\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lai_changed_stacked = lai_changed.stack(z=[\"lon\", \"lat\"])\n",
    "lai_notchanged_stacked = lai_notchanged.stack(z=[\"lon\", \"lat\"])\n",
    "changed_year_lai = lai_changed_stacked.isel(time=9)\n",
    "df = changed_year_lai.to_dataframe()\n",
    "coords = np.radians(df[[\"lat\", \"lon\"]])\n",
    "dist = DistanceMetric.get_metric(\"haversine\")\n",
    "tree = BallTree(coords, metric=dist)\n",
    "indices = tree.query_radius(coords, r=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_arr = []\n",
    "n = len(indices)\n",
    "for k in tqdm(range(n)):\n",
    "    # for k in tqdm(np.arange(302607, 302609)):\n",
    "\n",
    "    data = []\n",
    "    idx = indices[k]\n",
    "    # Get the changed LAI values of the centeral pixel\n",
    "    center_pixel = idx[np.where(idx == k)]\n",
    "    center_pixel_lai = lai_changed_stacked[:, center_pixel].values.squeeze()\n",
    "\n",
    "    # continue if the central pixel is nan\n",
    "    if np.isnan(center_pixel_lai).all():\n",
    "        continue\n",
    "\n",
    "    data.append(center_pixel_lai)\n",
    "    # Go over the neighboring pixels and get the LAI values of unchanged pixels\n",
    "    for i in range(len(idx)):\n",
    "        if idx[i] == center_pixel:\n",
    "            continue\n",
    "        tmp = lai_notchanged_stacked[:, idx[i]].values.squeeze()\n",
    "        # skip if the neighboring pixel is all nans\n",
    "        if np.isnan(tmp).all():\n",
    "            continue\n",
    "        data.append(tmp)\n",
    "    data_arr.append(np.array(data).transpose())\n",
    "\n",
    "\n",
    "with open(dir + \"working/data_arr\", \"wb\") as fp:\n",
    "    pickle.dump(data_arr, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.84     , 1.9200001, 2.0310001, ..., 1.7490001, 1.7500001,\n",
       "         1.7370001],\n",
       "        [1.8820001, 1.9990001, 1.9020001, ..., 1.932    , 1.789    ,\n",
       "         1.7900001],\n",
       "        [2.4780002, 2.2910001, 2.2700002, ..., 2.193    , 2.2080002,\n",
       "         2.2110002],\n",
       "        ...,\n",
       "        [1.96     , 2.3200002, 2.604    , ..., 1.4100001, 1.079    ,\n",
       "         1.34     ],\n",
       "        [2.033    , 2.713    , 2.2120001, ..., 1.575    , 1.243    ,\n",
       "         1.2830001],\n",
       "        [2.7380002, 3.226    , 2.9440002, ..., 3.025    , 3.0540001,\n",
       "         3.0700002]], dtype=float32),\n",
       " array([[1.6200001, 1.9200001, 2.4740002, ..., 1.8880001,       nan,\n",
       "         1.7490001],\n",
       "        [1.2310001, 1.9990001, 2.2470002, ..., 1.332    ,       nan,\n",
       "         1.932    ],\n",
       "        [2.197    , 2.2910001, 2.436    , ..., 1.3160001, 1.4070001,\n",
       "         2.193    ],\n",
       "        ...,\n",
       "        [2.049    , 2.3200002, 2.4540002, ..., 1.4120001,       nan,\n",
       "         1.4100001],\n",
       "        [2.8000002, 2.713    , 2.035    , ..., 1.036    , 0.349    ,\n",
       "         1.575    ],\n",
       "        [3.055    , 3.226    , 3.4670002, ..., 2.4750001, 2.105    ,\n",
       "         3.025    ]], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/hamiddashti/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/neighbors/_distance_metric.py:10: FutureWarning: sklearn.neighbors.DistanceMetric has been moved to sklearn.metrics.DistanceMetric in 1.0. This import path will be removed in 1.3\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "var = lai_changed.isel(time=9).values\n",
    "# var = arr2\n",
    "latitude = lai_changed[\"lat\"].values\n",
    "longitude = lai_changed[\"lon\"].values\n",
    "arr_val = arr.values\n",
    "df = (\n",
    "    pd.DataFrame(var, latitude, longitude)\n",
    "    .rename_axis(index=\"lat\", columns=\"lon\")\n",
    "    .stack()\n",
    "    .rename(\"lai\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Prepare data\n",
    "coords = np.radians(df[[\"lat\", \"lon\"]])\n",
    "\n",
    "dist = DistanceMetric.get_metric(\"haversine\")\n",
    "tree = BallTree(coords, metric=dist)\n",
    "indices = tree.query_radius(coords, r=0.003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lai_changed_stacked = lai_changed.stack(z=[\"lon\", \"lat\"])\n",
    "changed_year_lai = lai_changed_stacked.isel(time=9)\n",
    "df2 = changed_year_lai.to_dataframe()\n",
    "coords = np.radians(df2[[\"lat\", \"lon\"]])\n",
    "dist = DistanceMetric.get_metric(\"haversine\")\n",
    "tree = BallTree(coords, metric=dist)\n",
    "indices = tree.query_radius(coords, r=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36068"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "closes_index = ((df[\"lat\"] - 64.971).abs() + (df[\"lon\"] - (-120.423)).abs()).idxmin()\n",
    "df.loc[closes_index, \"index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>lai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>74.525002</td>\n",
       "      <td>-121.875000</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>74.525002</td>\n",
       "      <td>-121.824997</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>74.525002</td>\n",
       "      <td>-121.675003</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>74.525002</td>\n",
       "      <td>-121.574997</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>74.474998</td>\n",
       "      <td>-122.175003</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92042</th>\n",
       "      <td>92042</td>\n",
       "      <td>52.924999</td>\n",
       "      <td>-117.274994</td>\n",
       "      <td>1.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92043</th>\n",
       "      <td>92043</td>\n",
       "      <td>52.924999</td>\n",
       "      <td>-116.625000</td>\n",
       "      <td>2.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92044</th>\n",
       "      <td>92044</td>\n",
       "      <td>52.924999</td>\n",
       "      <td>-116.474998</td>\n",
       "      <td>2.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92045</th>\n",
       "      <td>92045</td>\n",
       "      <td>52.875000</td>\n",
       "      <td>-118.074997</td>\n",
       "      <td>2.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92046</th>\n",
       "      <td>92046</td>\n",
       "      <td>52.574997</td>\n",
       "      <td>-117.724998</td>\n",
       "      <td>2.283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92047 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        lat         lon    lai\n",
       "0          0  74.525002 -121.875000  0.758\n",
       "1          1  74.525002 -121.824997  0.685\n",
       "2          2  74.525002 -121.675003  0.739\n",
       "3          3  74.525002 -121.574997  0.714\n",
       "4          4  74.474998 -122.175003  0.308\n",
       "...      ...        ...         ...    ...\n",
       "92042  92042  52.924999 -117.274994  1.606\n",
       "92043  92043  52.924999 -116.625000  2.690\n",
       "92044  92044  52.924999 -116.474998  2.970\n",
       "92045  92045  52.875000 -118.074997  2.459\n",
       "92046  92046  52.574997 -117.724998  2.283\n",
       "\n",
       "[92047 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/hamiddashti/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/neighbors/_distance_metric.py:10: FutureWarning: sklearn.neighbors.DistanceMetric has been moved to sklearn.metrics.DistanceMetric in 1.0. This import path will be removed in 1.3\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_year = 2001\n",
    "lc_diff = percent_cover.diff(\"time\")\n",
    "event = lc_diff.sel(time=event_year)\n",
    "lcc = (event.where(event > 0)).sum(\"band\")\n",
    "thresh = 0.5\n",
    "lcc_dom = lcc.where(lcc > thresh)\n",
    "changed_pixels = np.isfinite(lcc_dom)\n",
    "\n",
    "# Index of pixels that have experienced significant LCC\n",
    "I = np.where(changed_pixels == True)\n",
    "print(len(I[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsize = 3\n",
    "win_size_half = int(np.floor(winsize / 2))\n",
    "changed_pixels_roll = (\n",
    "    changed_pixels.rolling({\"lat\": winsize, \"lon\": winsize}, center=True)\n",
    "    .construct({\"lat\": \"lat_dim\", \"lon\": \"lon_dim\"})\n",
    "    .values\n",
    ")\n",
    "lai_max_roll = (\n",
    "    lai_max.rolling({\"lat\": winsize, \"lon\": winsize}, center=True)\n",
    "    .construct({\"lat\": \"lat_dim\", \"lon\": \"lon_dim\"})\n",
    "    .values\n",
    ")\n",
    "\n",
    "ndvi_max_roll = (\n",
    "    ndvi_max.rolling({\"lat\": winsize, \"lon\": winsize}, center=True)\n",
    "    .construct({\"lat\": \"lat_dim\", \"lon\": \"lon_dim\"})\n",
    "    .values\n",
    ")\n",
    "swi_roll = (\n",
    "    swi.rolling({\"lat\": winsize, \"lon\": winsize}, center=True)\n",
    "    .construct({\"lat\": \"lat_dim\", \"lon\": \"lon_dim\"})\n",
    "    .values\n",
    ")\n",
    "\n",
    "\n",
    "percent_cover_roll = (\n",
    "    percent_cover.rolling({\"lat\": winsize, \"lon\": winsize}, center=True)\n",
    "    .construct({\"lat\": \"lat_dim\", \"lon\": \"lon_dim\"})\n",
    "    .values\n",
    ")\n",
    "\n",
    "lc_diff_roll = (\n",
    "    lc_diff.rolling({\"lat\": winsize, \"lon\": winsize}, center=True)\n",
    "    .construct({\"lat\": \"lat_dim\", \"lon\": \"lon_dim\"})\n",
    "    .values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = np.empty((winsize, winsize))\n",
    "windows[win_size_half, win_size_half] = np.nan\n",
    "lc_surronding = np.argwhere(np.isfinite(windows))\n",
    "\n",
    "# loop over pixels that have changed\n",
    "n = 5\n",
    "idx = [I[0][n], I[1][n]]\n",
    "# lc_diff[:,:,idx[0],idx[1]].to_pandas().plot(kind=\"bar\",stacked=True,figsize=(18,10))\n",
    "t = np.arange(1985, 2014)\n",
    "t_diff = np.arange(1986, 2014)\n",
    "event_index = np.where(t_diff == event_year)[0][0]\n",
    "\n",
    "i = idx[0]\n",
    "j = idx[1]\n",
    "\n",
    "percent_cover_roll_tmp = percent_cover_roll[:, :, i, j, :, :]  # (30, 10, 3, 3)\n",
    "lai_tmp = lai_max_roll[:, i, j, :, :]\n",
    "lc_diff_roll_tmp = lc_diff_roll[:, :, idx[0], idx[1], :, :]  # (28, 10, 3, 3)\n",
    "lai_max_roll_tmp = lai_max_roll[:, idx[0], idx[1], :, :]\n",
    "ndvi_max_roll_tmp = ndvi_max_roll[:, idx[0], idx[1], :, :]\n",
    "swi_roll_tmp = swi_roll[:, idx[0], idx[1], :, :]\n",
    "\n",
    "\n",
    "y = lai_tmp[:, win_size_half, win_size_half]\n",
    "\n",
    "# loop over neighbor pixels\n",
    "x_ndvi = []\n",
    "x_lai = []\n",
    "x_swi = []\n",
    "\n",
    "for k in range(len(lc_surronding)):\n",
    "    i_tmp = [lc_surronding[k][0], lc_surronding[k][1]]\n",
    "\n",
    "    m = 5  # years to look bac for LCC\n",
    "\n",
    "    s1 = percent_cover_roll_tmp[\n",
    "        event_index - (m - 1) : event_index + 1, :, i_tmp[0], i_tmp[1]\n",
    "    ]\n",
    "    s2 = np.isfinite(s1)\n",
    "    # Check if the land covers for the past m years before the events are the same\n",
    "    if (s2 == s2[0]).all():\n",
    "        # If above is true then look for LCC\n",
    "        d1 = lc_diff_roll_tmp[\n",
    "            event_index - (m - 1) : event_index, :, i_tmp[0], i_tmp[1]\n",
    "        ]\n",
    "        d1 = np.nan_to_num(d1, nan=0)\n",
    "\n",
    "        # Check if LC has not changed over the m years before the events\n",
    "        if (np.abs(d1) < 0.1).all():\n",
    "            ndvi_tmp = ndvi_max_roll_tmp[:, i_tmp[0], i_tmp[1]]\n",
    "            lai_tmp = lai_max_roll_tmp[:, i_tmp[0], i_tmp[1]]\n",
    "            swi_tmp = swi_roll_tmp[:, i_tmp[0], i_tmp[1]]\n",
    "            if ~np.isnan(ndvi_tmp).any():\n",
    "                x_ndvi.append(ndvi_tmp)\n",
    "            if ~np.isnan(lai_tmp).any():\n",
    "                x_lai.append(lai_tmp)\n",
    "\n",
    "            if ~np.isnan(swi_tmp).any():\n",
    "                x_swi.append(swi_tmp)\n",
    "\n",
    "x_ndvi = np.array(x_ndvi).transpose()\n",
    "x_lai = np.array(x_lai).transpose()\n",
    "x_swi = np.array(x_swi).transpose()\n",
    "# plt.plot(x_swi)\n",
    "plt.plot(t, x_lai)\n",
    "plt.plot(t, x_ndvi)\n",
    "plt.plot(t, y, linewidth=3, color=\"red\")\n",
    "plt.vlines(2008, ymin=0, ymax=4)\n",
    "\n",
    "yy = np.transpose(np.array(y, ndmin=2))\n",
    "data_lai = np.concatenate([yy, x_lai], axis=1)\n",
    "data_all = np.concatenate([yy, x_ndvi, x_lai], axis=1)\n",
    "\n",
    "# np.isnan(data).any()\n",
    "\n",
    "Data_all = pd.DataFrame(\n",
    "    data=data_all, index=pd.date_range(start=\"1985\", end=\"2014\", freq=\"A\")\n",
    ")\n",
    "Data_lai = pd.DataFrame(\n",
    "    data=data_lai, index=pd.date_range(start=\"1985\", end=\"2014\", freq=\"A\")\n",
    ")\n",
    "print(Data_lai.shape)\n",
    "print(Data_all.shape)\n",
    "np.isnan(yy).any()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_period = [0,16]\n",
    "# post_period = [17,len(t)-1]\n",
    "pre_period = [\"19851231\", \"20071231\"]\n",
    "post_period = [\"20081231\", \"20131231\"]\n",
    "\n",
    "ci = CausalImpact(\n",
    "    Data_lai,\n",
    "    pre_period,\n",
    "    post_period,\n",
    "    model_args={\n",
    "        \"fit_method\": \"hmc\",\n",
    "        #   'standardize': True,\n",
    "        \"prior_level_sd\": 0.01,\n",
    "    },\n",
    ")\n",
    "# ci = CausalImpact(Data_lai, pre_period, post_period)\n",
    "print(ci.summary())\n",
    "print(ci.summary(\"report\"))\n",
    "ci.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/WillianFuks/tfcausalimpact/master/tests/fixtures/arma_data.csv\"\n",
    ")[[\"y\", \"X\"]]\n",
    "data.iloc[70:, 0] += 5\n",
    "\n",
    "pre_period = [0, 69]\n",
    "post_period = [70, 99]\n",
    "\n",
    "ci = CausalImpact(data, pre_period, post_period)\n",
    "print(ci.summary())\n",
    "print(ci.summary(output=\"report\"))\n",
    "ci.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalimpact.misc import standardize\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "Data = pd.DataFrame(data)\n",
    "normed_data, _ = standardize(Data.astype(np.float32))\n",
    "\n",
    "obs_data = normed_data.iloc[:16, 0]\n",
    "linear_level = tfp.sts.LocalLinearTrend(observed_time_series=obs_data)\n",
    "linear_reg = tfp.sts.LinearRegression(\n",
    "    design_matrix=normed_data.iloc[:, 1:].values.reshape(-1, normed_data.shape[1] - 1)\n",
    ")\n",
    "model = tfp.sts.Sum([linear_level, linear_reg], observed_time_series=obs_data)\n",
    "ci = CausalImpact(data, pre_period, post_period, model=model)\n",
    "print(ci.summary())\n",
    "print(ci.summary(output=\"report\"))\n",
    "ci.plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6021ea7d074eda5ac97506998cf228896a59052f045ef557a4c9594641a51db9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
