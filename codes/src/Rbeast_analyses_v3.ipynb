{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization done!\n",
      "On the first run, check the CPU instruction set ... \n",
      "\n",
      "15\n",
      "CPU Vendor:\n",
      "    AMD         = No\n",
      "    Intel       = Yes\n",
      " \n",
      "OS Features:\n",
      "    OS AVX      = Yes\n",
      "    OS AVX512   = No\n",
      "\n",
      "Hardware Features:\n",
      "    MMX         = Yes\n",
      "    x64         = Yes\n",
      "    ABM         = Yes\n",
      "    RDRAND      = Yes\n",
      "    RDSEED      = No\n",
      "    BMI1        = Yes\n",
      "    BMI2        = Yes\n",
      "    ADX         = No\n",
      "    MPX         = No\n",
      "    PREFETCHW   = No\n",
      "    PREFETCHWT1 = No\n",
      "    RDPID       = No\n",
      "    GFNI        = No\n",
      "    VAES        = No\n",
      "\n",
      "SIMD: 128-bit\n",
      "    SSE         = Yes\n",
      "    SSE2        = Yes\n",
      "    SSE3        = Yes\n",
      "    SSSE3       = Yes\n",
      "    SSE4a       = No\n",
      "    SSE4.1      = Yes\n",
      "    SSE4.2      = Yes\n",
      "    AES-NI      = Yes\n",
      "    SHA         = No\n",
      "\n",
      "SIMD: 256-bit\n",
      "    AVX         = Yes\n",
      "    XOP         = No\n",
      "    FMA3        = Yes\n",
      "    FMA4        = No\n",
      "    AVX2        = Yes\n",
      "\n",
      "SIMD: 512-bit\n",
      "    AVX512-F         = No\n",
      "    AVX512-CD        = No\n",
      "    AVX512-PF        = No\n",
      "    AVX512-ER        = No\n",
      "    AVX512-VL        = No\n",
      "    AVX512-BW        = No\n",
      "    AVX512-DQ        = No\n",
      "    AVX512-IFMA      = No\n",
      "    AVX512-VBMI      = No\n",
      "    AVX512-VPOPCNTDQ = No\n",
      "    AVX512-4FMAPS    = No\n",
      "    AVX512-4VNNIW    = No\n",
      "    AVX512-VBMI2     = No\n",
      "    AVX512-VPCLMUL   = No\n",
      "    AVX512-VNNI      = No\n",
      "    AVX512-BITALG    = No\n",
      "    AVX512-BF16      = No\n",
      "\n",
      "Summary\n",
      "    Safe to use AVX:     Yes\n",
      "    Safe to use AVX512:  No\n",
      "\n",
      "Cache ID 0:\n",
      "- Level: 1\n",
      "- Type: Data Cache\n",
      "- Sets: 64\n",
      "- System Coherency Line Size: 64 bytes\n",
      "- Physical Line partitions: 1\n",
      "- Ways of associativity: 8\n",
      "- Total Size: 32768 bytes (32 kb)\n",
      "- Is fully associative: false\n",
      "- Is Self Initializing: true\n",
      "\n",
      "Cache ID 1:\n",
      "- Level: 1\n",
      "- Type: Instruction Cache\n",
      "- Sets: 64\n",
      "- System Coherency Line Size: 64 bytes\n",
      "- Physical Line partitions: 1\n",
      "- Ways of associativity: 8\n",
      "- Total Size: 32768 bytes (32 kb)\n",
      "- Is fully associative: false\n",
      "- Is Self Initializing: true\n",
      "\n",
      "Cache ID 2:\n",
      "- Level: 2\n",
      "- Type: Unified Cache\n",
      "- Sets: 512\n",
      "- System Coherency Line Size: 64 bytes\n",
      "- Physical Line partitions: 1\n",
      "- Ways of associativity: 8\n",
      "- Total Size: 262144 bytes (256 kb)\n",
      "- Is fully associative: false\n",
      "- Is Self Initializing: true\n",
      "\n",
      "Cache ID 3:\n",
      "- Level: 3\n",
      "- Type: Unified Cache\n",
      "- Sets: 16384\n",
      "- System Coherency Line Size: 64 bytes\n",
      "- Physical Line partitions: 1\n",
      "- Ways of associativity: 20\n",
      "- Total Size: 20971520 bytes (20480 kb)\n",
      "- Is fully associative: false\n",
      "- Is Self Initializing: true\n",
      "\n",
      "CPU checking result: The AVX2-enabled library is used ...\n",
      "\n",
      "ars1111111111111111x\n",
      "WARNING: metadata$isRegularOrdered is not specified. A default 'metadata$isRegularOrdered=TRUE' is assumed.\n",
      "WARNING: when metadata$isRegualrOrdered=TRUE, the input data is assumed to be regular and ordered in time AND the times of individual datapoints are determined fully by 'metadata$startTime' and 'metadata$deltaTime'. But deltaTime is missing and a default value 1 is used!\n",
      "Parallel computing: thread#1  generated ... \n",
      "Parallel computing: thread#2  generated ... \n",
      "Parallel computing: thread#3  generated ... \n",
      "Parallel computing: thread#4  generated ... \n",
      "Parallel computing: thread#5  generated ... \n",
      "Parallel computing: thread#6  generated ... \n",
      "Parallel computing: thread#7  generated ... \n",
      "Parallel computing: thread#8  generated ... \n",
      "Parallel computing: thread#9  generated ... \n",
      "Parallel computing: thread#10 generated ... \n",
      "Parallel computing: thread#11 generated ... \n",
      "Parallel computing: thread#12 generated ... \n",
      "Parallel computing: thread#13 generated ... \n",
      "Parallel computing: thread#14 generated ... \n",
      "Parallel computing: thread#15 generated ... \n",
      "Parallel computing: thread#16 generated ... \n",
      "Parallel computing: thread#17 generated ... \n",
      "Parallel computing: thread#18 generated ... \n",
      "Parallel computing: thread#19 generated ... \n",
      "Parallel computing: thread#20 generated ... \n",
      "Parallel computing: thread#21 generated ... \n",
      "Parallel computing: thread#22 generated ... \n",
      "Parallel computing: thread#23 generated ... \n",
      "Parallel computing: thread#24 generated ... \n",
      "Parallel computing: thread#25 generated ... \n",
      "Parallel computing: thread#26 generated ... \n",
      "Parallel computing: thread#27 generated ... \n",
      "Parallel computing: thread#28 generated ... \n",
      "Parallel computing: thread#29 generated ... \n",
      "Parallel computing: thread#30 generated ... \n",
      "Parallel computing: thread#31 generated ... \n",
      "Parallel computing: thread#32 generated ... \n",
      "Parallel computing: thread#33 generated ... \n",
      "Parallel computing: thread#34 generated ... \n",
      "Parallel computing: thread#35 generated ... \n",
      "Parallel computing: thread#36 generated ... \n",
      "Parallel computing: thread#37 generated ... \n",
      "Parallel computing: thread#38 generated ... \n",
      "Parallel computing: thread#39 generated ... \n",
      "Parallel computing: thread#40 generated ... \n",
      "Parallel computing: thread#41 generated ... \n",
      "Parallel computing: thread#42 generated ... \n",
      "Parallel computing: thread#43 generated ... \n",
      "Parallel computing: thread#44 generated ... \n",
      "Parallel computing: thread#45 generated ... \n",
      "Parallel computing: thread#46 generated ... \n",
      "Parallel computing: thread#47 generated ... \n",
      "Parallel computing: thread#48 generated ... \n",
      "Parallel computing: thread#49 generated ... \n",
      "Parallel computing: thread#50 generated ... \n",
      "Parallel computing: thread#51 generated ... \n",
      "Parallel computing: thread#52 generated ... \n",
      "Parallel computing: thread#53 generated ... \n",
      "Parallel computing: thread#54 generated ... \n",
      "Parallel computing: thread#55 generated ... \n",
      "Parallel computing: thread#56 generated ... \n",
      "Parallel computing: thread#57 generated ... \n",
      "Parallel computing: thread#58 generated ... \n",
      "Parallel computing: thread#59 generated ... \n",
      "Parallel computing: thread#60 generated ... \n",
      "Parallel computing: thread#61 generated ... \n",
      "Parallel computing: thread#62 generated ... \n",
      "Parallel computing: thread#63 generated ... \n",
      "Parallel computing: thread#64 generated ... \n",
      "Rbeast: Waiting on 64 threads...\n",
      " 100.0%done<Remaining00hrs00min00sec>[==============================================]\n",
      "Finalizing ... \n",
      "Rbeast: Thread #0  finished ... \n",
      "Rbeast: Thread #1  finished ... \n",
      "Rbeast: Thread #2  finished ... \n",
      "Rbeast: Thread #3  finished ... \n",
      "Rbeast: Thread #4  finished ... \n",
      "Rbeast: Thread #5  finished ... \n",
      "Rbeast: Thread #6  finished ... \n",
      "Rbeast: Thread #7  finished ... \n",
      "Rbeast: Thread #8  finished ... \n",
      "Rbeast: Thread #9  finished ... \n",
      "Rbeast: Thread #10 finished ... \n",
      "Rbeast: Thread #11 finished ... \n",
      "Rbeast: Thread #12 finished ... \n",
      "Rbeast: Thread #13 finished ... \n",
      "Rbeast: Thread #14 finished ... \n",
      "Rbeast: Thread #15 finished ... \n",
      "Rbeast: Thread #16 finished ... \n",
      "Rbeast: Thread #17 finished ... \n",
      "Rbeast: Thread #18 finished ... \n",
      "Rbeast: Thread #19 finished ... \n",
      "Rbeast: Thread #20 finished ... \n",
      "Rbeast: Thread #21 finished ... \n",
      "Rbeast: Thread #22 finished ... \n",
      "Rbeast: Thread #23 finished ... \n",
      "Rbeast: Thread #24 finished ... \n",
      "Rbeast: Thread #25 finished ... \n",
      "Rbeast: Thread #26 finished ... \n",
      "Rbeast: Thread #27 finished ... \n",
      "Rbeast: Thread #28 finished ... \n",
      "Rbeast: Thread #29 finished ... \n",
      "Rbeast: Thread #30 finished ... \n",
      "Rbeast: Thread #31 finished ... \n",
      "Rbeast: Thread #32 finished ... \n",
      "Rbeast: Thread #33 finished ... \n",
      "Rbeast: Thread #34 finished ... \n",
      "Rbeast: Thread #35 finished ... \n",
      "Rbeast: Thread #36 finished ... \n",
      "Rbeast: Thread #37 finished ... \n",
      "Rbeast: Thread #38 finished ... \n",
      "Rbeast: Thread #39 finished ... \n",
      "Rbeast: Thread #40 finished ... \n",
      "Rbeast: Thread #41 finished ... \n",
      "Rbeast: Thread #42 finished ... \n",
      "Rbeast: Thread #43 finished ... \n",
      "Rbeast: Thread #44 finished ... \n",
      "Rbeast: Thread #45 finished ... \n",
      "Rbeast: Thread #46 finished ... \n",
      "Rbeast: Thread #47 finished ... \n",
      "Rbeast: Thread #48 finished ... \n",
      "Rbeast: Thread #49 finished ... \n",
      "Rbeast: Thread #50 finished ... \n",
      "Rbeast: Thread #51 finished ... \n",
      "Rbeast: Thread #52 finished ... \n",
      "Rbeast: Thread #53 finished ... \n",
      "Rbeast: Thread #54 finished ... \n",
      "Rbeast: Thread #55 finished ... \n",
      "Rbeast: Thread #56 finished ... \n",
      "Rbeast: Thread #57 finished ... \n",
      "Rbeast: Thread #58 finished ... \n",
      "Rbeast: Thread #59 finished ... \n",
      "Rbeast: Thread #60 finished ... \n",
      "Rbeast: Thread #61 finished ... \n",
      "Rbeast: Thread #62 finished ... \n",
      "Rbeast: Thread #63 finished ... \n",
      "\n",
      "Rbeast: Waited on 64 threads. Done.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import Rbeast as rb\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dir = \"/data/home/hamiddashti/hamid/nasa_above/greeness/\"\n",
    "out_dir = \"/data/home/hamiddashti/hamid/nasa_above/greeness/data/processed_data/\"\n",
    "arr = np.arange(0, 448 * 1348).reshape(448, 1348, order=\"F\")\n",
    "t = pd.date_range(start=\"1984\", end=\"2014\", freq=\"A-Dec\").year\n",
    "\n",
    "lai = xr.open_dataarray(\n",
    "    dir + \"data/processed_data/noaa_nc/lai_fapar/resampled/lai_growing_mean.nc\"\n",
    ")\n",
    "lai = lai.rename({\"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "\n",
    "percent = xr.open_dataset(dir + \"data/processed_data/percent_cover/percent_cover.nc\")[\n",
    "    \"__xarray_dataarray_variable__\"\n",
    "]\n",
    "changed_pixels_mask = xr.open_dataarray(\n",
    "    dir + \"data/processed_data/noaa_nc/lai_fapar/trend/changed_pixels.nc\"\n",
    ")\n",
    "# lai_data = lai.isel(latitude=200,longitude=400).values\n",
    "lai_changed = lai.where(changed_pixels_mask)\n",
    "\n",
    "ct = xr.open_dataset(dir + \"data/processed_data/confusion_tables/ct_all_years.nc\")\n",
    "pix_id = ct[\"PIX_INDEX\"]\n",
    "lc1 = ct[\"LC_2003\"]\n",
    "lc2 = ct[\"LC_2013\"]\n",
    "ctn = ct[\"NORMALIZED_CONFUSION\"] * 100\n",
    "dlcc = ct[\"DLCC\"] * -1  #\n",
    "conf = ct[\"CONFUSION\"]\n",
    "\n",
    "metadata = rb.args(whichDimIsTime=1, season=\"none\", startTime=1984)\n",
    "mcmc = rb.args(seed=1)\n",
    "extra = rb.args(  # a set of options to specify the outputs or computational configurations\n",
    "    dumpInputData=True,  # make a copy of the aggregated input data in the beast ouput\n",
    "    numThreadsPerCPU=2,  # Paralell  computing: use 2 threads per cpu core\n",
    "    numParThreads=0,  # `0` means using all CPU cores: total num of ParThreads = numThreadsPerCPU * core Num\n",
    "    printOptions=False,\n",
    ")\n",
    "season = \"none\"\n",
    "out2 = rb.beast123(lai_changed.values, metadata, [], mcmc, extra)\n",
    "\n",
    "cp = out2.trend.cp\n",
    "ncp_med = np.round(out2.trend.ncp)\n",
    "\n",
    "# for i in np.arange(0,ncp_med.shape[0]*ncp_med.shape[1]):\n",
    "ncp1 = np.argwhere(ncp_med == 1)\n",
    "cp1 = np.squeeze(cp[0, :, :])\n",
    "\n",
    "occ_mat = np.zeros((10, 10, 448 * 1348))\n",
    "ct_percent_mat = np.zeros((10, 10, 448 * 1348))\n",
    "ct_percent_mat[:] = np.nan\n",
    "percent_mat = np.zeros((10, 10, 448 * 1348))\n",
    "percent_mat[:] = np.nan\n",
    "ui = np.triu_indices(10, k=1)\n",
    "li = np.tril_indices(10, k=-1)\n",
    "no_lcc = 0\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8.387598\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in np.arange(0, cp1.shape[0]):\n",
    "    for j in np.arange(0, cp1.shape[1]):\n",
    "        if np.isnan(cp1[i, j]):\n",
    "            continue\n",
    "        cp_time = int(cp1[i, j])\n",
    "        idx = arr[i, j]\n",
    "        id = np.where(pix_id.isel(time=0).values == idx)[0]\n",
    "        ct_sel = ctn.isel(ID=id).sel(time=cp_time).squeeze().values\n",
    "        np.fill_diagonal(ct_sel, 0)\n",
    "        I_max = np.unravel_index(ct_sel.argmax(), ct_sel.shape)\n",
    "        if I_max == (0, 0):\n",
    "            no_lcc += 1\n",
    "            continue\n",
    "        abs_lcc = abs(ct_sel[ui] - ct_sel[li])\n",
    "        net_lcc = abs_lcc.sum()\n",
    "\n",
    "        if net_lcc <2:\n",
    "            continue\n",
    "        percent_mat[I_max + (idx,)] = net_lcc\n",
    "        I_max_reversed = I_max[::-1]\n",
    "        max_ct = np.argmax(abs_lcc)\n",
    "        ct_percent_mat[I_max + (idx,)] = max(\n",
    "            ct_sel[li[0][max_ct], li[1][max_ct]], ct_sel[ui[0][max_ct], ui[1][max_ct]]\n",
    "        )\n",
    "        occ_mat[I_max + (idx,)] += 1\n",
    "\n",
    "        counter = counter + 1\n",
    "\n",
    "names = [\n",
    "    \"EF\",\n",
    "    \"DF\",\n",
    "    \"shrub\",\n",
    "    \"Herb\",\n",
    "    \"sparse\",\n",
    "    \"Barren\",\n",
    "    \"Fen\",\n",
    "    \"Bog\",\n",
    "    \"Shallow/Littoral\",\n",
    "    \"Water\",\n",
    "]\n",
    "occurance = occ_mat.sum(axis=2)\n",
    "\n",
    "df = pd.DataFrame(data=occurance, index=names, columns=names)\n",
    "percent_mat_data = percent_mat[~np.isnan(percent_mat)]\n",
    "percent_mat_data_df = pd.DataFrame(percent_mat_data)\n",
    "percent_mat_data_df.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geospatial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58d4357dc51a73699c5449b037ed9e8ebf9460004e4993ef846dc1036514c650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
